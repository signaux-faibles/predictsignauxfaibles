{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "burning-blade",
   "metadata": {},
   "source": [
    "Producing lists out of prediction files\n",
    "===\n",
    "This notebooks aims to produce lists as JSON file with each entry containing fields:\n",
    "- siret\n",
    "- periode\n",
    "- score\n",
    "- timestamp\n",
    "- algo\n",
    "- alert\n",
    "\n",
    "It takes as inputs a set of CSV prediction files produced by `predictsignauxfaibles`, typically:\n",
    "- one file corresponding to the \"default\" model\n",
    "- one file corresponding to the \"small\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level to INFO\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Import required libraries and modules\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from predictsignauxfaibles.config import OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-attendance",
   "metadata": {},
   "source": [
    "Functions to make the alert flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_models(model_list: list):\n",
    "    \"\"\"\n",
    "    Builds a single list of predicted probabilities based on several models,\n",
    "    listed by decreasing order of priority.\n",
    "    For a given SIRET, if no prediction is found for the first model in the list,\n",
    "    a prediction for the next model will be considered, etc\n",
    "    Arguments:\n",
    "        model_list: list\n",
    "            A list of pandas DataFrame containing, at least, the following columns: siren, predicted_probability\n",
    "    \"\"\"\n",
    "    merged = model_list.pop()\n",
    "    for model_id in range(len(model_list)):\n",
    "        model = model_list.pop()\n",
    "        merged = pd.merge(model, merged, left_on='siret', right_on='siret', how='outer', suffixes=(\"_main\", \"_supp\"))          \n",
    "        merged[\"predicted_probability\"] = merged[\"predicted_probability_main\"].fillna(merged[\"predicted_probability_supp\"])\n",
    "        merged = merged[[\"siret\", \"predicted_probability\"]]\n",
    "    return merged\n",
    "\n",
    "def assign_flag(pred: float, t_rouge: float, t_orange: float):\n",
    "    if pred > t_rouge:\n",
    "        return \"Alerte seuil F1\"\n",
    "    elif pred > t_orange:\n",
    "        return \"Alerte seuil F2\"\n",
    "    return \"Pas d'alerte\"\n",
    "\n",
    "def split_predictions(preds: pd.DataFrame, t_rouge: float, t_orange: float):\n",
    "    \"\"\"\n",
    "    Generates red/orange/green flags based on two thresholds\n",
    "    \"\"\"\n",
    "    assert(\"predicted_probability\" in preds.columns.tolist())\n",
    "    preds[\"alert\"] = preds[\"predicted_probability\"].apply(lambda x: assign_flag(x, t_rouge, t_orange))\n",
    "    \n",
    "    num_rouge = sum(preds[\"predicted_probability\"] > t_rouge)\n",
    "    num_orange = sum(preds[\"predicted_probability\"] > t_orange)\n",
    "    num_orange -= num_rouge\n",
    "    print(f\"{num_rouge} rouge ({round(num_rouge/preds.shape[0] * 100, 2)}%)\")\n",
    "    print(f\"{num_orange} orange ({round(num_orange/preds.shape[0] * 100, 2)}%)\")\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-canal",
   "metadata": {},
   "source": [
    "Let's load CSV data produced by a run with the default model and a run with the small model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = pd.read_csv(\"/home/simon.lebastard/predictsignauxfaibles/predictsignauxfaibles/model_runs/20210507-195755/predictions-20210507-195755.csv\")\n",
    "small = pd.read_csv(\"/home/simon.lebastard/predictsignauxfaibles/predictsignauxfaibles/model_runs/20210507-195735/predictions-20210507-195735.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_models(model_list = [default, small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = split_predictions(merged, t_rouge= 0.75, t_orange = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "run_path = Path(OUTPUT_FOLDER) / f\"{list_id}\"\n",
    "run_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(run_path / \"scores.json\", \"w\") as stats_file:\n",
    "    stats_file.write(json.dumps(merged.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-substitute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
