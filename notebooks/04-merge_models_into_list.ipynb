{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indian-indianapolis",
   "metadata": {},
   "source": [
    "Producing lists out of prediction files\n",
    "===\n",
    "This notebooks aims to produce lists as JSON file with each entry containing fields:\n",
    "- siret\n",
    "- periode\n",
    "- score\n",
    "- timestamp\n",
    "- algo\n",
    "- alert\n",
    "\n",
    "It takes as inputs a set of CSV prediction files produced by `predictsignauxfaibles`, typically:\n",
    "- one file corresponding to the \"default\" model\n",
    "- one file corresponding to the \"small\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level to INFO\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Import required libraries and modules\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from predictsignauxfaibles.config import OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-savage",
   "metadata": {},
   "source": [
    "Functions to make the alert flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictsignauxfaibles.make_list import merge_models, assign_flag, make_alert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-disabled",
   "metadata": {},
   "source": [
    "Let's load CSV data produced by a run with the default model and a run with the small model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = pd.read_csv(\"/home/simon.lebastard/predictsignauxfaibles/predictsignauxfaibles/model_runs/20210507-195755/predictions-20210507-195755.csv\")\n",
    "small = pd.read_csv(\"/home/simon.lebastard/predictsignauxfaibles/predictsignauxfaibles/model_runs/20210507-195735/predictions-20210507-195735.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_models(model_list = [default, small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_splits_size(merged, t_rouge= 0.75, t_orange = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"alert\"] = merged[\"predicted_probability\"].apply(\n",
    "    lambda x: assign_flag(x, t_rouge=0.75, t_orange=0.3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "run_path = Path(OUTPUT_FOLDER) / f\"{list_id}\"\n",
    "run_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(run_path / \"scores.json\", \"w\") as stats_file:\n",
    "    stats_file.write(json.dumps(merged.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-masters",
   "metadata": {},
   "source": [
    "Preparing a new dummy list\n",
    "---\n",
    "From what was output by the succesful run of `python3 -m predictsignauxfaibles` using the new function explain, let's produce a list that we can communicate to the front-end team.\n",
    "\n",
    "Collection `Scores` on MongoDB needs to receive that looks like this:\n",
    "```\n",
    "{\n",
    "    \"siret\": \"12345678901234\",\n",
    "    \"periode\": \"2019-01-01\",\n",
    "    \"score\": 0.996714234,\n",
    "    \"batch\": \"1904\",\n",
    "    \"timestamp\": 2019-01-01T14:56:58.418+00:00,\n",
    "    \"algo\": \"algo_avec_urssaf\",\n",
    "    \"alert\" :\"Alerte seuil F1\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"alert\"] = predictions.predicted_probability.apply(decision_function, args = (.45, .38))\n",
    "merged[\"periode\"] = \"2020-02-01\"\n",
    "merged[\"batch\"] = \"<BATCH_NAME>\"\n",
    "merged[\"algo\"] = conf.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = merged.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "js = json.dumps(pred_dict) #allow_nan=False\n",
    "with open(\"/home/simon.lebastard/predictsignauxfaibles/data/explain/scores_export_test.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(js)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
