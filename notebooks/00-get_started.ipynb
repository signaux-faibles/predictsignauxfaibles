{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signaux Faibles - Data Science DÃ©mo\n",
    "\n",
    "The purpose of this repo is to get your started using the `predictsignauxfaibles` repository.\n",
    "\n",
    "In this notebook, we will retrieve some data in a `SFDataset` object, train a basic `SFModelGAM` on it and make some predictions using our trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "You should have created a `.env` file at the root of your local copy of the repo. The required entries are documented in `.env.example`. _Never_ commit your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root of the repo to PYTHONPATH\n",
    "import sys\n",
    "sys.path.append(\"../.\")\n",
    "\n",
    "# Set logging level to INFO\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Import required libraries and modules\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "from lib.data import SFDataset\n",
    "from lib.models import SFModelGAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you have access to MongoDB. If you are ensure how to do this, just ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "The easiest way to load a dataset is via the `SFDataset` class. It can be instantiated in two ways :\n",
    "- via its constructor method `dataset = SFDataset(...)`, better for developping and exploring the data\n",
    "- via a yaml configuration file `dataset = SFDataset.from_config_file(\"../models/rocketscience/model.yml\")`, which is best for ensuring reproducibility and for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        -----------------------\n",
       "        Signaux Faibles Dataset\n",
       "        -----------------------\n",
       "\n",
       "        batch_id : 2009_5\n",
       "        ---------- \n",
       "\n",
       "        Fields:\n",
       "        -------\n",
       "            ['siret', 'periode', 'outcome', 'montant_part_ouvriere_past_1', 'montant_part_patronale_past_1', 'ratio_dette']\n",
       "\n",
       "        MongoDB Aggregate Pipeline:\n",
       "        ---------------------------\n",
       "            []\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_FEATURES = [\n",
    "    \"montant_part_ouvriere_past_1\",\n",
    "    \"montant_part_patronale_past_1\",\n",
    "    \"ratio_dette\",\n",
    "]\n",
    "\n",
    "# It's always a good idea to query periods, siret, and outcomes too\n",
    "FIELDS_TO_QUERY =  [\"siret\", \"periode\", \"outcome\"] + MY_FEATURES\n",
    "\n",
    "dataset = SFDataset(\n",
    "    date_min=\"2015-01-01\",\n",
    "    date_max=\"2016-06-30\",\n",
    "    fields=FIELDS_TO_QUERY,\n",
    "    sample_size=10_000,\n",
    "    batch_id=\"2009_5\"\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created an (empty) dataset. Use the `fetch_data` method to fill it. The data is stored as a Pandas DataFrame in the `.data` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siret</th>\n",
       "      <th>periode</th>\n",
       "      <th>outcome</th>\n",
       "      <th>montant_part_ouvriere_past_1</th>\n",
       "      <th>montant_part_patronale_past_1</th>\n",
       "      <th>ratio_dette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32657703800028</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32018930100015</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33037752400203</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44937840500012</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42481349100018</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            siret    periode  outcome  montant_part_ouvriere_past_1  \\\n",
       "0  32657703800028 2015-04-01    False                           0.0   \n",
       "1  32018930100015 2016-04-01    False                           0.0   \n",
       "2  33037752400203 2015-11-01    False                           0.0   \n",
       "3  44937840500012 2016-05-01    False                           0.0   \n",
       "4  42481349100018 2015-08-01    False                           0.0   \n",
       "\n",
       "   montant_part_patronale_past_1  ratio_dette  \n",
       "0                            0.0          0.0  \n",
       "1                            0.0          0.0  \n",
       "2                            0.0          NaN  \n",
       "3                            0.0          0.0  \n",
       "4                            0.0          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.fetch_data()\n",
    "\n",
    "dataset.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `prepare_data()` for standard data preprocessing. This method :\n",
    "- creates a `siren` column from the `siret`\n",
    "- fills missing values with their defaults defined in `config.py`\n",
    "- drops any remaining observation with NAs\n",
    "\n",
    "\n",
    "You can also manipulate `dataset.data` yourself when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating a `siren` column\n",
      "INFO:root:Replacing missing data with default values\n",
      "INFO:root:Drop observations with missing required fields.\n",
      "INFO:root:Removing NAs from dataset.\n",
      "INFO:root:Number of observations before: 10000\n",
      "INFO:root:Number of observations after: 10000\n"
     ]
    }
   ],
   "source": [
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "Just like datasets, models can be instantiated in two ways :\n",
    "- via its constructor method `dataset = SFModel(...)`, better for developping and exploring the data\n",
    "- via a yaml configuration file `dataset = SFModel.from_config_file(\"../models/rocketscience/model.yml\")`, which is best for ensuring reproducibility and for production use.\n",
    "\n",
    "Once you are done developping a new model, don't forget to write your configuration file so that your coworkers can reproduce and audit your work :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam = SFModelGAM(dataset, features=MY_FEATURES, target=\"outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model using its `train` method. The (trained) model is stored in the `.model` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticGAM                                                                                               \n",
      "=============================================== ==========================================================\n",
      "Distribution:                      BinomialDist Effective DoF:                                       7.648\n",
      "Link Function:                        LogitLink Log Likelihood:                                  -417.5112\n",
      "Number of Samples:                         7000 AIC:                                              850.3184\n",
      "                                                AICc:                                             850.3422\n",
      "                                                UBRE:                                               2.1223\n",
      "                                                Scale:                                                 1.0\n",
      "                                                Pseudo R-Squared:                                   0.4499\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [0.6]                20           4.1          2.55e-02     *           \n",
      "s(1)                              [0.6]                20           2.8          6.83e-08     ***         \n",
      "s(2)                              [0.6]                20           0.7          0.00e+00     ***         \n",
      "intercept                                              1            0.0          2.89e-15     ***         \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentviers/.pyenv/versions/sf/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return dist.levels/(mu*(dist.levels - mu))\n",
      "/Users/vincentviers/.pyenv/versions/sf/lib/python3.8/site-packages/pygam/pygam.py:591: RuntimeWarning: invalid value encountered in multiply\n",
      "  return sp.sparse.diags((self.link.gradient(mu, self.distribution)**2 *\n",
      "<ipython-input-6-95fba91d4b3c>:2: UserWarning: KNOWN BUG: p-values computed in this summary are likely much smaller than they should be. \n",
      " \n",
      "Please do not make inferences based on these values! \n",
      "\n",
      "Collaborate on a solution, and stay up to date at: \n",
      "github.com/dswah/pyGAM/issues/163 \n",
      "\n",
      "  gam.model.summary()\n"
     ]
    }
   ],
   "source": [
    "gam.train()\n",
    "gam.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9886666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "Work in progress :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf",
   "language": "python",
   "name": "sf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
