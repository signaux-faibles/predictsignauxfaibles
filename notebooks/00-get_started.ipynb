{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signaux Faibles - Data Science DÃ©mo\n",
    "\n",
    "The purpose of this repo is to get your started using the `predictsignauxfaibles` repository.\n",
    "\n",
    "In this notebook, we will retrieve some data in a `SFDataset` object, train a basic `SFModelGAM` on it and make some predictions using our trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "You should have created a `.env` file at the root of your local copy of the repo. The required entries are documented in `.env.example`. _Never_ commit your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root of the repo to PYTHONPATH\n",
    "import sys\n",
    "sys.path.append(\"../.\")\n",
    "\n",
    "# mute warnings (! do not do this when working in prod !)\n",
    "# TODO: fix pyGAM warnings https://github.com/signaux-faibles/predictsignauxfaibles/issues/12\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set logging level to INFO\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Import required libraries and modules\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "from lib.data import SFDataset\n",
    "from lib.models import SFModelGAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you have access to MongoDB. If you are ensure how to do this, just ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "The easiest way to load a dataset is via the `SFDataset` class. It can be instantiated in two ways :\n",
    "- via its constructor method `dataset = SFDataset(...)`, better for developping and exploring the data\n",
    "- via a yaml configuration file `dataset = SFDataset.from_config_file(\"../models/rocketscience/model.yml\")`, which is best for ensuring reproducibility and for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        -----------------------\n",
       "        Signaux Faibles Dataset\n",
       "        -----------------------\n",
       "\n",
       "        batch_id : 2012_paydex\n",
       "        ---------- \n",
       "\n",
       "        Fields:\n",
       "        -------\n",
       "            ['siret', 'siren', 'periode', 'outcome', 'montant_part_ouvriere_past_1', 'montant_part_patronale_past_1', 'ratio_dette']\n",
       "\n",
       "        MongoDB Aggregate Pipeline:\n",
       "        ---------------------------\n",
       "            []\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_FEATURES = [\n",
    "    \"montant_part_ouvriere_past_1\",\n",
    "    \"montant_part_patronale_past_1\",\n",
    "    \"ratio_dette\",\n",
    "]\n",
    "\n",
    "# It's always a good idea to query periods, siret, and outcomes too\n",
    "FIELDS_TO_QUERY =  [\"siret\", \"siren\", \"periode\", \"outcome\"] + MY_FEATURES\n",
    "\n",
    "dataset = SFDataset(\n",
    "    date_min=\"2015-01-01\",\n",
    "    date_max=\"2016-06-30\",\n",
    "    fields=FIELDS_TO_QUERY,\n",
    "    sample_size=10_000\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created an (empty) dataset. Use the `fetch_data` method to fill it. The data is stored as a Pandas DataFrame in the `.data` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periode</th>\n",
       "      <th>outcome</th>\n",
       "      <th>montant_part_ouvriere_past_1</th>\n",
       "      <th>montant_part_patronale_past_1</th>\n",
       "      <th>ratio_dette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     periode  outcome  montant_part_ouvriere_past_1  \\\n",
       "0 2015-04-01    False                           0.0   \n",
       "1 2016-04-01    False                           0.0   \n",
       "2 2015-11-01    False                           0.0   \n",
       "3 2016-05-01    False                           0.0   \n",
       "4 2015-04-01    False                           0.0   \n",
       "\n",
       "   montant_part_patronale_past_1  ratio_dette  \n",
       "0                            0.0          0.0  \n",
       "1                            0.0          0.0  \n",
       "2                            0.0          NaN  \n",
       "3                            0.0          0.0  \n",
       "4                            0.0          0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.fetch_data()\n",
    "\n",
    "# hide siret and siren as the repo is public\n",
    "dataset.data.head().loc[:, ~dataset.data.columns.isin([\"siret\", \"siren\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `prepare_data()` for standard data preprocessing. This method :\n",
    "- creates a `siren` column from the `siret`\n",
    "- fills missing values with their defaults defined in `config.py`\n",
    "- drops any remaining observation with NAs\n",
    "\n",
    "\n",
    "You can also manipulate `dataset.data` yourself if you want to perform your own transformation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Replacing missing data with default values\n",
      "INFO:root:Drop observations with missing required fields.\n",
      "INFO:root:Removing NAs from dataset.\n",
      "INFO:root:Number of observations before: 10000\n",
      "INFO:root:Number of observations after: 9854\n",
      "INFO:root:Resetting index for DataFrame.\n"
     ]
    }
   ],
   "source": [
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "Just like datasets, models can be instantiated in two ways :\n",
    "- via its constructor method `dataset = SFModel(...)`, better for developping and exploring the data\n",
    "- via a yaml configuration file `dataset = SFModel.from_config_file(\"../models/rocketscience/model.yml\")`, which is best for ensuring reproducibility and for production use.\n",
    "\n",
    "Once you are done developping a new model, don't forget to write your configuration file so that your coworkers can reproduce and audit your work :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam = SFModelGAM(dataset, features=MY_FEATURES, target=\"outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model using its `train` method. The (trained) model is stored in the `.model` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam.train()\n",
    "gam.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Signaux Faible uses a fairly specific way to evaluate a model. This evaluation process is implemented in `SFModelEvaluator`.\n",
    "\n",
    "First, start by querying a validation dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = SFDataset(\n",
    "        date_min=\"2018-01-01\",\n",
    "        date_max=\"2018-06-30\",\n",
    "        fields=FIELDS_TO_QUERY,\n",
    "        sample_size=5_000\n",
    ")\n",
    "validation_set.fetch_data().prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cross-validation evaluation method on our model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.model_selection import SFModelEvaluator\n",
    "\n",
    "cv_scores = SFModelEvaluator(model = gam).cv_evaluation(num_folds=5, validate_set=validation_set)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average performance of the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score = sum(cv_scores.values()) / len(cv_scores)\n",
    "round(average_score, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = validation_set.data[MY_FEATURES]\n",
    "\n",
    "# predict probabilities (a float)\n",
    "pred_probas = gam.predict_proba(new_data)\n",
    "\n",
    "# predict outcome (True/False)\n",
    "pred_outcomes = gam.predict(new_data)\n",
    "\n",
    "pred_probas[:5], pred_outcomes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "Work in progress :) In the meantime, you can use `pickle` to serialize any python object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf",
   "language": "python",
   "name": "sf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
