{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "crucial-network",
   "metadata": {},
   "source": [
    "# Model evaluation - Optimal thresholding on default probas\n",
    "In this notebook, we use a LogReg trained on 1M SIRETs, evaluated on 250k SIRETs.<br>\n",
    "We compute $f_{\\beta}$ scores, balanced accuracy and select thresholds optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level to INFO\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Import required libraries and modules\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "from types import ModuleType\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve, fbeta_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from predictsignauxfaibles.config import IGNORE_NA\n",
    "from predictsignauxfaibles.data import SFDataset\n",
    "from predictsignauxfaibles.evaluate import evaluate, make_precision_recall_curve, make_thresholds_from_fbeta, make_thresholds_from_conditions\n",
    "from predictsignauxfaibles.make_list import merge_models, assign_flag, make_alert\n",
    "from predictsignauxfaibles.pipelines import run_pipeline\n",
    "from predictsignauxfaibles.utils import load_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-parish",
   "metadata": {},
   "source": [
    "## Loading predictions from csv, splitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING MODELS FROM FILES\n",
    "\n",
    "model_runs = {\n",
    "    \"default\": \"/home/simon.lebastard/predictsignauxfaibles/predictsignauxfaibles/model_runs/default_20210519-172348\",\n",
    "    \"small\": \"/home/simon.lebastard/predictsignauxfaibles/predictsignauxfaibles/model_runs/small_20210519-172421\"\n",
    "}\n",
    "\n",
    "## DEFAULT MODEL PIPELINE\n",
    "\n",
    "default = pd.read_csv(f\"{model_runs['default']}/predictions.csv\")\n",
    "default_mapper_unpickled =  pickle.load(\n",
    "    open( f\"{model_runs['default']}/model_comp0.pickle\",\n",
    "        \"rb\"\n",
    "        )\n",
    ")\n",
    "default_mapper = default_mapper_unpickled[1]\n",
    "default_model_unpickled = pickle.load(\n",
    "    open( f\"{model_runs['default']}/model_comp1.pickle\",\n",
    "        \"rb\"\n",
    "        )\n",
    ")\n",
    "default_model = default_model_unpickled[1]\n",
    "\n",
    "default_pp = Pipeline(\n",
    "    [(\"transform_dataframe\", default_mapper), (\"fit_model\", default_model)]\n",
    ")\n",
    "\n",
    "## SMALL MODEL PIPELINE\n",
    "\n",
    "small = pd.read_csv(f\"{model_runs['small']}/predictions.csv\")\n",
    "small_mapper_unpickled = pickle.load(\n",
    "    open( f\"{model_runs['small']}/model_comp0.pickle\",\n",
    "        \"rb\"\n",
    "        )\n",
    ")\n",
    "small_mapper = small_mapper_unpickled[1]\n",
    "small_model_unpickled = pickle.load(\n",
    "    open( f\"{model_runs['small']}/model_comp1.pickle\",\n",
    "        \"rb\"\n",
    "        )\n",
    ")\n",
    "small_model = small_model_unpickled[1]\n",
    "\n",
    "small_pp = Pipeline(\n",
    "    [(\"transform_dataframe\", small_mapper), (\"fit_model\", small_model)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "default.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-height",
   "metadata": {},
   "source": [
    "### Making list for the merged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_models(model_list = [default, small])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-rates",
   "metadata": {},
   "source": [
    "## Computing precision/recall graph as a function of classification thresholds - Default model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-zambia",
   "metadata": {},
   "source": [
    "Inspecting the model from saved pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-block",
   "metadata": {},
   "source": [
    "Let's load a test set from which we can use the output to measure our performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_conf = load_conf(model_name=\"default\")\n",
    "test = default_conf.TEST_DATASET\n",
    "test.sample_size = 2.5e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.fetch_data()\n",
    "test.data = pd.read_csv(f\"/home/simon.lebastard/predictsignauxfaibles/data/prod_mars2021/2103_prod_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.replace_missing_data().remove_na(ignore=IGNORE_NA)\n",
    "test.data = run_pipeline(test.data, default_conf.TRANSFO_PIPELINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-thirty",
   "metadata": {},
   "source": [
    "((((((((((((((((((\n",
    "#### Code for local execution (no calling functions from make_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-temperature",
   "metadata": {},
   "source": [
    "A couple of quicks checks/diagnoses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.data.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*test.data.groupby(by=\"outcome\").siret.count()/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-madrid",
   "metadata": {},
   "source": [
    "Isolating transformed features on one hand, outcomes on the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.data[set(test.data.columns).difference(set([\"outcome\"]))]\n",
    "test_outcomes = test.data[\"outcome\"].astype(int).to_numpy()\n",
    "test_features_mapped = default_mapper.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-jacksonville",
   "metadata": {},
   "source": [
    "Now let's plot the Type1-Type2 graph and select threholds based on our requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresh = precision_recall_curve(test_outcomes, default_lr.predict_proba(test_features_mapped)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-accreditation",
   "metadata": {},
   "source": [
    "))))))))))))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-stopping",
   "metadata": {},
   "source": [
    "## Option 1: Determine the thresholds by hand, looking at the Type2-Type1 errors plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresh = make_precision_recall_curve(\n",
    "    test,\n",
    "    default_pp, # to be built from the mapper as step 0 and the lr as step 1\n",
    "    default_conf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "type_2 = 1 - recall\n",
    "type_1 = 1 - precision\n",
    "\n",
    "ax.scatter(\n",
    "    type_1,\n",
    "    type_2,\n",
    "    label = \"logreg\"\n",
    ");\n",
    "\n",
    "plt.axhline(y=0.37, color='orange', linestyle='-')\n",
    "plt.axvline(x=0.07, color='red', linestyle='-')\n",
    "\n",
    "ax.set_xlabel('Type 1 error', fontsize=16)\n",
    "ax.set_ylabel('Type 2 error', fontsize=16)\n",
    "\n",
    "ax.legend(fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-egyptian",
   "metadata": {},
   "source": [
    "On peut sélectionner un seuil F1 (rouge) et un seuil F2 (orange) à partir de cette courbe:\n",
    "- pour la liste F1, on cherche à maximiser la précision, puisqe la liste en question doit être la plus pertinent possible et contenir des entreprises \"prioritaires\". Cette liste minimise donc les faux positifs, favorise la précision et minimise donc l'erreur de type 1.\n",
    "- la liste F2 doit se charger de minimiser les faux négatifs, et est donc plus orienter sur la maximisation du recall. Il s'agit ici de minimiser l'erreur de type 2.\n",
    "\n",
    "Pour $t_{F1}$, on choisit une valeur qui donne une erreur de type 1 petite tout en étant la plus indulgente possible pour l'erreur de type 2. C'est typiquement ce qu'un point de courbure maximale va réaliser. Ici $t_{F1}=0.07$ semble assez satisfaisant (ligne verticale rouge ci-dessus).\n",
    "\n",
    "Pour $t_{F2}$, on choisir au contraire une valeur de courbe (négative) minimale, tout en satisfaisant déjà une erreur de type 2 suffisament faible. Ici $t_{F2}=0.37$ semble assez satisfaisant (ligne horizontale orange ci-dessus)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-constitutional",
   "metadata": {},
   "source": [
    "## Option 2: Select thresholds by maximising a f-beta (with beta specified for each alert level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tester\n",
    "(t_F1, t_F2) = make_thresholds_from_fbeta(\n",
    "    test,\n",
    "    default_pp,\n",
    "    default_conf,\n",
    "    beta_F1 = 0.5,\n",
    "    beta_F2 = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-sheep",
   "metadata": {},
   "source": [
    "Sur le dataset de test chargé depuis /home/simon.lebastard/predictsignauxfaibles/data/prod_mars2021/2103_prod_data_test.csv (250k):<br>\n",
    "F1 - $\\beta=0.5$ - Optimal threshold: $t_{F1}=0.876$ - $f_{0.5}=0.683$<br>\n",
    "F2 - $\\beta=2$ - Optimal threshold: $t_{F2}=0.220$ - $f_{2}=0.495$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    default_pp,\n",
    "    test,\n",
    "    beta=2,\n",
    "    thresh=0.22\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-michigan",
   "metadata": {},
   "source": [
    "((((((((((((((((<br>\n",
    "Local code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_beta_rec = []\n",
    "f_beta_prc = []\n",
    "\n",
    "for thr_id, thr in enumerate(thresh.tolist()):\n",
    "    f_beta_rec.append(\n",
    "        fbeta_score(y_true=test_outcomes, y_pred=(default_lr.predict_proba(test_features_mapped)[:,1]>=thr), beta=2)\n",
    "    )\n",
    "    f_beta_prc.append(\n",
    "        fbeta_score(y_true=test_outcomes, y_pred=(default_lr.predict_proba(test_features_mapped)[:,1]>=thr), beta=0.6)\n",
    "    )\n",
    "    \n",
    "f_beta_rec = np.array(f_beta_rec)\n",
    "f_beta_prc = np.array(f_beta_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.plot(\n",
    "    thresh,\n",
    "    f_beta_rec,\n",
    "    color=\"r\",\n",
    "    label=\"beta=2\"\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    thresh,\n",
    "    f_beta_prc,\n",
    "    color=\"b\",\n",
    "    label=\"beta=0.6\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Decision threshold\", fontsize=18)\n",
    "ax.set_ylabel(\"f_beta\", fontsize=18)\n",
    "\n",
    "ax.legend(fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_F1_id = np.argmax(f_beta_prc)\n",
    "t_F1 = thresh[t_F1_id]\n",
    "\n",
    "t_F2_id = np.argmax(f_beta_rec)\n",
    "t_F2 = thresh[t_F2_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-quantum",
   "metadata": {},
   "source": [
    "))))))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_F2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-disabled",
   "metadata": {},
   "source": [
    "## 3. Select threshold by specifying a minimal precision for T1 alerts and a minimal recall for T1 + T2 alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tester\n",
    "(t_F1_c, t_F2_c) = make_thresholds_from_conditions(\n",
    "    test,\n",
    "    default_pp,\n",
    "    default_conf,\n",
    "    min_precision_F1 = 0.93,\n",
    "    min_recall_F2 = 0.63\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_precision_F1 = 0.93\n",
    "min_recall_F2 = 0.63\n",
    "\n",
    "# Find the minimum threshold such that precision is greater than min_precision_F1\n",
    "t_F1_id = np.argmax(precision>=min_precision_F1)\n",
    "t_F1_c = thresh[t_F1_id]\n",
    "\n",
    "# Find the maximum threshold such that recall is greater than min_recall_F2\n",
    "t_F2_id = np.argmax(recall[::-1][:-1]>=min_recall_F2)\n",
    "t_F2_c = thresh[::-1][t_F2_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_F1_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_F2_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-flooring",
   "metadata": {},
   "source": [
    "Sur le dataset de test chargé depuis /home/simon.lebastard/predictsignauxfaibles/data/prod_mars2021/2103_prod_data_test.csv (250k):<br>\n",
    "F1 - $t_{F1}=0.921$ garantit une précision de 93% pour la liste F1 (rouge)<br>\n",
    "F2 - $t_{F2}=0.124$ garantit un recall de 63% pour la liste F2 (orange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-macro",
   "metadata": {},
   "source": [
    "## Research - Can we build a threshold selection criterion based on the variations of recall % threhold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the first-order derivative of the type-2 error\n",
    "fod_recall = (recall[:-1] - np.roll(recall[:-1],1))/(thresh - np.roll(thresh,1))\n",
    "fod_recall = fod_recall[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fod_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.scatter(\n",
    "    thresh[:-81],\n",
    "    fod_recall[:-80],\n",
    "    label = \"logreg\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalL_maxvar_id = np.argmin(fod_recall[:-80])\n",
    "recall_maxvar = fod_recall[recalL_maxvar_id]\n",
    "\n",
    "recall_maxvar_precision = precision[recalL_maxvar_id]\n",
    "recall_maxvar_recall = recall[recalL_maxvar_id]\n",
    "recall_maxvar_thresh = thresh[recalL_maxvar_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_maxvar_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_maxvar_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_maxvar_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-couple",
   "metadata": {},
   "source": [
    "For now, we'll stick to manual selection based on the two types of error above, or maybe based on the maximisation of Fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-russian",
   "metadata": {},
   "source": [
    "## Building json to be sent to collection Scores on MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_full = scores_raw[[\"siret\",\"siren\",\"predicted_probability_full\"]]\n",
    "scores_small = scores_raw[[\"siret\",\"siren\",\"predicted_probability_small\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_full.rename(columns={\"predicted_probability_full\": \"predicted_probability\"}, inplace=True)\n",
    "scores_small.rename(columns={\"predicted_probability_small\": \"predicted_probability\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = merge_models(model_list = [scores_full, scores_small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
