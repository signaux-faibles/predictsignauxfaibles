{
    "metadata": {
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8-final",
        },
        "orig_nbformat": 2,
        "kernelspec": {
            "name": "python368jvsc74a57bd0619141f40d6660e90435fdea452ff8c8a3cfa2ce2d42e30ecc199b88a9b310ca",
            "display_name": "Python 3.6.8 64-bit ('env_predictSF')",
        },
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "source": [
                "# Analyse des scores de risque Signaux Faibles - Création d'indicateurs régionaux\n",
                "Dans le cadre d'une demande du Ministère du Travail, Signaux Faibles réalise une analyse agrégée aux niveaux géographiques de la région et du département, pour fournir différents indicateurs de risque territorialisés.\n",
                "\n",
                "Ce notebook vise à charger les données provenant de nos prédictions de risque pour Mars 2020, et à produire des indicateurs agrégés qui seront ultérieurement aposés sur des fonds de cartographie.",
            ],
            "cell_type": "markdown",
            "metadata": {},
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": ["%config Completer.use_jedi = False"],
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os.path\n",
                "from pymongo import MongoClient\n",
                "from pymongo.cursor import Cursor\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from datetime import datetime\n",
                "import pytz\n",
                "\n",
                "# Set logging level to INFO\n",
                "import logging\n",
                "logger = logging.getLogger()\n",
                "logger.setLevel(logging.INFO)\n",
                "\n",
                "from predictsignauxfaibles.utils import MongoDBQuery, MongoParams\n",
                "import predictsignauxfaibles.config as global_config\n",
                "\n",
                "import config as cab_config\n",
                "import utils\n",
            ],
        },
        {
            "source": ["# Part 1 - Métriques à mars 2020 (modèle)"],
            "cell_type": "markdown",
            "metadata": {},
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "load_features_from_file = True\n",
                "load_scores_from_file = True\n",
                'features_path = "/home/simon.lebastard/predictsignauxfaibles/data/features_2103.json"\n',
                'scores_path = "/home/simon.lebastard/predictsignauxfaibles/data/scores_2103.json"\n',
                'postproc_path = "/home/simon.lebastard/predictsignauxfaibles/data/postproc_2103.json"',
            ],
        },
        {
            "source": [
                "## Fetching features and scores data\n",
                "### Option 1: Fetch data from each dataset",
            ],
            "cell_type": "markdown",
            "metadata": {},
        },
        {
            "source": [
                'features = utils.load_features(date_min="2020-02-01", date_max="2020-02-28", from_file=True, filepath=features_path)\n',
                'logging.info(f"Loaded {features.shape[0]} rows and {features.shape[1]} columns")',
            ],
            "cell_type": "code",
            "metadata": {},
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "INFO:root:Succesfully loaded Features data from /home/simon.lebastard/predictsignauxfaibles/data/features_2103.json\n",
                        "INFO:root:Loaded 956765 rows and 31 columns\n",
                    ],
                }
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "INFO:root:Succesfully loaded Scores data from /home/simon.lebastard/predictsignauxfaibles/data/scores_2103.json\n",
                        "INFO:root:Loaded 657296 rows and 7 columns\n",
                    ],
                }
            ],
            "source": [
                'scores = utils.load_scores(batch_name="2102_altares", algo_name="mars2021_v0", from_file=True, filepath=scores_path)\n',
                'logging.info(f"Loaded {scores.shape[0]} rows and {scores.shape[1]} columns")',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                'features["periode"] = features.periode.apply(utils.datetime_to_str)\n',
                'scores["periode"] = scores.periode.apply(utils.datetime_to_str)',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.merge(scores, features, on=['siret', 'periode'], how='inner')\n"
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "array([None, 'Hauts-de-France', 'Pays de la Loire',\n",
                            "       \"Provence-Alpes-Côte d'Azur\", 'Bretagne', 'Occitanie', 'Normandie',\n",
                            "       'Bourgogne-Franche-Comté', 'Grand Est', 'Auvergne-Rhône-Alpes',\n",
                            "       'Centre-Val de Loire', 'Île-de-France', 'Nouvelle-Aquitaine', ''],\n",
                            "      dtype=object)",
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8,
                }
            ],
            "source": ["df.region.unique()"],
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def map_region_to_code(reg_name):\n",
                "    if reg_name is None or reg_name=='':\n",
                "        return None\n",
                "    elif reg_name not in cab_config.CODES_REGION.keys():\n",
                "        return None\n",
                "    else:\n",
                "        return cab_config.CODES_REGION[reg_name]\n",
                "\n",
                'df["code_reg"] = df.region.apply(map_region_to_code)',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not os.path.isfile(postproc_path):\n",
                '    logging.info("Saving joined post-processed data to disk...")\n',
                '    df.to_json(postproc_path, orient="records", default_handler=str)\n',
                '    logging.info(f"Saved to {postproc_path}")',
            ],
        },
        {
            "source": ["### Option 2: Load data directly from df stored on disk"],
            "cell_type": "markdown",
            "metadata": {},
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.isfile(postproc_path):\n",
                '    print("Loading post-processed data to disk")\n',
                '    df = pd.read_json(postproc_path, orient="records")',
            ],
        },
        {
            "source": [
                "## Aggregation of region-wide features\n",
                "\n",
                "Niveaux de granularité considérés:\n",
                "- région\n",
                "- département\n",
                "\n",
                "Pour chaque niveau de granularité:\n",
                "- compter le nombre d'établissements flaguées rouge par région\n",
                "- compter le nombre d'établissements flaguées orange par région\n",
                "- compter le nombre d'établissements flaguées en rouge OU en orange\n",
                "- rapporter ces nombre d'établissements au nombre total d'établissements dans la zone géographique\n",
                "- compter le nombre de défaillances effectives sur une période donnée, et calculer le ratio correspondants\n",
                "\n",
                "Pour toutes les grandeurs calculées précédemment, calculer des équivalents en nombre d'employés concernés.\n",
                "\n",
                "Pour les établissements ayant un risque de défaillance modéré ou fort (flagguée en rouge OU en orange), communiquer:\n",
                "- ratio $\\frac{dette_{ouvriere}}{cotisation}$ moyen\n",
                "- recours moyen à l'activité partielle\n",
                "\n",
                "On pourra éventuellement ajouter à ces premières métriques:\n",
                "- des ratios financiers provenant de la DE de la Banque de France\n",
                "- le nombre de jour moyen de retard de paiement aux fournisseurs (donnée Paydex)\n",
                "\n",
                "### Preprocessing steps",
            ],
            "cell_type": "markdown",
            "metadata": {},
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess(df):\n",
                "    # create an outcome flag based only on failures since the beginning of the COVID crisis\n",
                '    df["failure"] = (df["time_til_failure"]>=0) & (df["time_til_failure"]<12) # todo: automatiser le nombre de mois à regarder vers l\'avant: entre mars 2020 et <THIS_MONTH>\n',
                '    df["failure"] = df.failure.astype(int)\n',
                "\n",
                "    # encode alert level into integer\n",
                '    df["alert_flag"] = df.alert.replace({"Pas d\'alerte": 0, "Alerte seuil F1": 1, "Alerte seuil F2": 2})\n',
                '    df["alert_bin"] = (df.alert_flag > 0)\n',
                "\n",
                "    # ratio dette/cotisation sur la part salariale des cotisations sociales\n",
                '    df["ratio_dette_ouvriere"] = df["montant_part_ouvriere"] / df["cotisation"]\n',
                '    df["ratio_dette_patronale"] = df["montant_part_patronale"] / df["cotisation"]\n',
                "    return df\n",
                "\n",
                "def replace_nans(df, replace_dct):\n",
                "    for field, rpl in replace_dct.items():\n",
                "        df[field].fillna(value=rpl, inplace=True)",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": ["replace_nans(df, cab_config.NAN_RPL)\n", "df = preprocess(df)"],
        },
        {
            "source": [
                "Vérification des effectifs par catégorie:\n",
                "- entrée en procédure collective\n",
                "- flagging par l'algorithme SF\n",
                "- flagging binaire par l'algorithme SF (True si un établissement est flagué en rouge OU en orange, False si l'établissement est flagué Vert, ie non flagué)",
            ],
            "cell_type": "markdown",
            "metadata": {},
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ['df.groupby(by=["failure"]).siret.count()'],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ['df.groupby(by=["alert_flag"]).siret.count()'],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ['df.groupby(by=["alert_bin"]).siret.count()'],
        },
        {
            "source": ["### Building aggregation dataframe"],
            "cell_type": "markdown",
            "metadata": {},
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["cab_config.FEATURES_LIST"],
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "def aggregate_stats(geo_attr, outcome_attr):\n",
                '    assert outcome_attr in ["alert_flag", "alert_bin", "failure", "outcome"]\n',
                "\n",
                '    risk_ape3_stats = df.groupby(by=[geo_attr,outcome_attr,"libelle_naf","libelle_ape3"]).agg(\n',
                "        siret_count=('siret', 'count'),\n",
                "        effectif_tot=('effectif', 'sum'),\n",
                "    )\n",
                '    risk_naf_stats = df.groupby(by=[geo_attr,outcome_attr,"libelle_naf"]).agg(\n',
                "        siret_count=('siret', 'count'),\n",
                "        effectif_tot=('effectif', 'sum')\n",
                "    )\n",
                "    risk_stats = df.groupby(by=[geo_attr,outcome_attr]).agg(\n",
                "        siret_count=('siret', 'count'),\n",
                "        effectif_tot=('effectif', 'sum'),\n",
                "        ratiodette_ouvr_avg=('ratio_dette_ouvriere', 'mean'),\n",
                "        ratiodette_patr_avg=('ratio_dette_patronale', 'mean'),\n",
                "        ratiodette_avg=('ratio_dette', 'mean'),\n",
                "        apart_autr_avg=('apart_heures_autorisees', 'mean'),\n",
                "        apart_cons_avg=('apart_heures_consommees', 'mean'),\n",
                "        apart_cumcons_avg=('apart_heures_consommees_cumulees', 'mean'),\n",
                "        paydex_avg=('paydex_nb_jours', 'mean'),\n",
                "        taux_endettement_avg=('taux_endettement', 'mean'),\n",
                "    )\n",
                "    national_stats = df.groupby(by=[outcome_attr]).agg(\n",
                "        siret_count=('siret', 'count'),\n",
                "        effectif_tot=('effectif', 'sum'),\n",
                "        ratiodette_ouvr_avg=('ratio_dette_ouvriere', 'mean'),\n",
                "        ratiodette_patr_avg=('ratio_dette_patronale', 'mean'),\n",
                "        ratiodette_avg=('ratio_dette', 'mean'),\n",
                "        apart_autr_avg=('apart_heures_autorisees', 'mean'),\n",
                "        apart_cons_avg=('apart_heures_consommees', 'mean'),\n",
                "        apart_cumcons_avg=('apart_heures_consommees_cumulees', 'mean'),\n",
                "        paydex_avg=('paydex_nb_jours', 'mean'),\n",
                "        taux_endettement_avg=('taux_endettement', 'mean'),\n",
                "    )\n",
                "\n",
                "    # Calcul du ratio des effectifs/établissements par rapport au total de la zone géographique\n",
                "    risk_stats['siret_rate'] = risk_stats.siret_count / risk_stats.groupby(by=geo_attr).siret_count.sum()\n",
                "    national_stats['siret_rate'] = national_stats.siret_count / national_stats.siret_count.sum()\n",
                "\n",
                "    risk_stats['effectif_rate'] = risk_stats.siret_count / risk_stats.groupby(by=geo_attr).effectif_tot.sum()\n",
                "    national_stats['effectif_rate'] = national_stats.effectif_tot / national_stats.effectif_tot.sum()\n",
                "\n",
                "    # Analyses sectorielles - Nombre d'employés\n",
                "    risk_stats['ape3_mostatrisk_eff'] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values(\"libelle_naf\").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,outcome_attr]).effectif_tot.idxmax()\n",
                "    risk_stats['ape3_mostatrisk_eff'] = risk_stats['ape3_mostatrisk_eff'].apply(lambda x: x[3] if isinstance(x, tuple) else \"None\")\n",
                "    risk_stats['ape3_risk_eff'] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values(\"libelle_naf\").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,outcome_attr]).effectif_tot.max()\n",
                "\n",
                '    ape3_risk_overrepresentation_eff = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].effectif_tot.unstack().div(risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,"libelle_naf","libelle_ape3"]).agg({"effectif_tot": \'sum\'}).effectif_tot, axis=0).stack()\n',
                "    risk_stats['ape3_risk_eff_most_overrepresented'] = ape3_risk_overrepresentation_eff.groupby(by=[geo_attr,outcome_attr]).idxmax()\n",
                "    risk_stats['ape3_risk_eff_most_overrepresented'] = risk_stats['ape3_risk_eff_most_overrepresented'].apply(lambda x: x[3] if isinstance(x, tuple) else \"None\")\n",
                "\n",
                "    for naf in cab_config.NAF_INDUSTRY:\n",
                '        risk_stats[f"ape3_mostatrisk_eff_{naf}"] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf")==naf].groupby(by=[geo_attr,outcome_attr]).effectif_tot.idxmax()\n',
                '        risk_stats[f"ape3_mostatrisk_eff_{naf}"] = risk_stats[f"ape3_mostatrisk_eff_{naf}"].apply(lambda x: x[3] if isinstance(x, tuple) else "None")\n',
                '        risk_stats[f"ape3_risk_eff_{naf}"] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,outcome_attr]).effectif_tot.max()\n',
                "\n",
                '        ape3_risk_overrepresentation_eff = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf")==naf].effectif_tot.unstack().div(risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf")==naf].groupby(by=[geo_attr,"libelle_naf","libelle_ape3"]).agg({"effectif_tot": \'sum\'}).effectif_tot, axis=0).stack()\n',
                '        risk_stats[f"ape3_risk_eff_most_overrepresented_{naf}"] = ape3_risk_overrepresentation_eff.groupby(by=[geo_attr,outcome_attr]).idxmax()\n',
                '        risk_stats[f"ape3_risk_eff_most_overrepresented_{naf}"] = risk_stats[f"ape3_risk_eff_most_overrepresented_{naf}"].apply(lambda x: x[3] if isinstance(x, tuple) else "None")\n',
                "\n",
                "    risk_stats['naf_mostatrisk_eff_abs'] = risk_naf_stats.groupby(by=[geo_attr,outcome_attr]).effectif_tot.idxmax()\n",
                "    risk_stats['naf_mostatrisk_eff_abs'] = risk_stats.naf_mostatrisk_eff.apply(lambda x: x[2] if isinstance(x, tuple) else \"None\")\n",
                "    risk_stats['naf_risk_eff_abs'] = risk_naf_stats.groupby(by=[geo_attr,outcome_attr]).effectif_tot.max()\n",
                "\n",
                '    naf_risk_overrepresentation_eff = risk_naf_stats.effectif_tot.unstack().div(risk_naf_stats.groupby(by=[geo_attr,"libelle_naf"]).agg({"effectif_tot": \'sum\'}).effectif_tot, axis=0).stack()\n',
                "    risk_stats['naf_risk_eff_most_overrepresented'] = naf_risk_overrepresentation_eff.groupby(by=[geo_attr,outcome_attr]).idxmax()\n",
                "    risk_stats['naf_risk_eff_most_overrepresented'] = risk_stats['naf_risk_eff_most_overrepresented'].apply(lambda x: x[3] if isinstance(x, tuple) else \"None\")\n",
                "\n",
                "    # Analyses sectorielles - Nombre d'établissements\n",
                "    risk_stats['ape3_mostatrisk_etab'] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values(\"libelle_naf\").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,outcome_attr]).siret_count.idxmax()\n",
                "    risk_stats['ape3_mostatrisk_etab'] = risk_stats['ape3_mostatrisk_etab'].apply(lambda x: x[3] if isinstance(x, tuple) else \"None\")\n",
                "    risk_stats['ape3_risk_etab'] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values(\"libelle_naf\").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,outcome_attr]).siret_count.max()\n",
                "\n",
                '    ape3_risk_overrepresentation_etab = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].siret_count.unstack().div(risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,"libelle_naf","libelle_ape3"]).agg({"effectif_tot": \'sum\'}).siret_count, axis=0).stack()\n',
                "    risk_stats['ape3_risk_etab_most_overrepresented'] = ape3_risk_overrepresentation_etab.groupby(by=[geo_attr,outcome_attr]).idxmax()\n",
                "    risk_stats['ape3_risk_etab_most_overrepresented'] = risk_stats['ape3_risk_etab_most_overrepresented'].apply(lambda x: x[3] if isinstance(x, tuple) else \"None\")\n",
                "\n",
                "    for naf in cab_config.NAF_INDUSTRY:\n",
                '        risk_stats[f"ape3_mostatrisk_etab_{naf}"] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf")==naf].groupby(by=[geo_attr,outcome_attr]).siret_count.idxmax()\n',
                '        risk_stats[f"ape3_mostatrisk_etab_{naf}"] = risk_stats[f"ape3_mostatrisk_etab_{naf}"].apply(lambda x: x[3] if isinstance(x, tuple) else "None")\n',
                '        risk_stats[f"ape3_risk_etab_{naf}"] = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf").isin([cab_config.LIBELLE_NAF[code] for code in cab_config.NAF_INDUSTRY])].groupby(by=[geo_attr,outcome_attr]).siret_count.max()\n',
                "\n",
                '        ape3_risk_overrepresentation_etab = risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf")==naf].siret_count.unstack().div(risk_ape3_stats.loc[risk_ape3_stats.index.get_level_values("libelle_naf")==naf].groupby(by=[geo_attr,"libelle_naf","libelle_ape3"]).agg({"effectif_tot": \'sum\'}).siret_count, axis=0).stack()\n',
                '        risk_stats[f"ape3_risk_etab_most_overrepresented_{naf}"] = ape3_risk_overrepresentation_etab.groupby(by=[geo_attr,outcome_attr]).idxmax()\n',
                '        risk_stats[f"ape3_risk_etab_most_overrepresented_{naf}"] = risk_stats[f"ape3_risk_etab_most_overrepresented_{naf}"].apply(lambda x: x[3] if isinstance(x, tuple) else "None")\n',
                "\n",
                "    risk_stats['naf_mostatrisk_etab_abs'] = risk_naf_stats.groupby(by=[geo_attr,outcome_attr]).siret_count.idxmax()\n",
                "    risk_stats['naf_mostatrisk_etab_abs'] = risk_stats.naf_mostatrisk_etab.apply(lambda x: x[2] if isinstance(x, tuple) else \"None\")\n",
                "    risk_stats['naf_risk_etab_abs'] = risk_naf_stats.groupby(by=[geo_attr,outcome_attr]).siret_count.max()\n",
                "\n",
                '    naf_risk_overrepresentation_etab = risk_naf_stats.siret_count.unstack().div(risk_naf_stats.groupby(by=[geo_attr,"libelle_naf"]).agg({"effectif_tot": \'sum\'}).siret_count, axis=0).stack()\n',
                "    risk_stats['naf_risk_etab_most_overrepresented'] = naf_risk_overrepresentation_etab.groupby(by=[geo_attr,outcome_attr]).idxmax()\n",
                "    risk_stats['naf_risk_etab_most_overrepresented'] = risk_stats['naf_risk_etab_most_overrepresented'].apply(lambda x: x[3] if isinstance(x, tuple) else \"None\")\n",
                "\n",
                "    # Rapport des indicateurs calculés à l'échelle nationale: on calcule la sur/sous-représentativité par rapport à la France entière\n",
                "    risk_stats['siret_rate_to_ntl_avg_to_ntl_avg'] = (risk_stats.siret_rate - national_stats.siret_rate) / national_stats.siret_rate\n",
                "    risk_stats['effectif_rate_to_ntl_avg_to_ntl_avg'] = (risk_stats.effectif_rate - national_stats.effectif_rate) / national_stats.effectif_rate\n",
                "    risk_stats['ratiodette_ouvr_avg_to_ntl_avg'] = (risk_stats.ratiodette_ouvr_avg - national_stats.ratiodette_ouvr_avg) / national_stats.ratiodette_ouvr_avg\n",
                "    risk_stats['ratiodette_patr_avg_to_ntl_avg'] = (risk_stats.ratiodette_patr_avg - national_stats.ratiodette_patr_avg) / national_stats.ratiodette_patr_avg\n",
                "    risk_stats['ratiodette_avg_to_ntl_avg'] = (risk_stats.ratiodette_avg - national_stats.ratiodette_avg) / national_stats.ratiodette_avg\n",
                "    risk_stats['apart_autr_avg_to_ntl_avg'] = (risk_stats.apart_autr_avg - national_stats.apart_autr_avg) / national_stats.apart_autr_avg\n",
                "    risk_stats['apart_cons_avg_to_ntl_avg'] = (risk_stats.apart_cons_avg - national_stats.apart_cons_avg) / national_stats.apart_cons_avg\n",
                "    risk_stats['apart_cumcons_avg_to_ntl_avg'] = (risk_stats.apart_cumcons_avg - national_stats.apart_cumcons_avg) / national_stats.apart_cumcons_avg\n",
                "    risk_stats['paydex_avg_to_ntl_avg'] = (risk_stats.paydex_avg - national_stats.paydex_avg) / national_stats.paydex_avg\n",
                "    risk_stats['taux_endettement_avg_to_ntl_avg'] = (risk_stats.taux_endettement_avg - national_stats.taux_endettement_avg) / national_stats.taux_endettement_avg\n",
                "\n",
                "    return risk_stats",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "IndexError",
                    "evalue": "list index out of range",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        '\u001b[0;32m<ipython-input-21-1eae9f865492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg_risk_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"region"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"alert_flag"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreg_riskbin_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"region"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"alert_bin"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreg_fail_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"region"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"failure"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdpt_risk_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"departement"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m"alert_flag"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n',
                        '\u001b[0;32m<ipython-input-20-752e9afea548>\u001b[0m in \u001b[0;36maggregate_stats\u001b[0;34m(geo_attr, outcome_attr)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mrisk_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf"ape3_risk_eff_{naf}"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_ape3_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrisk_ape3_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m"libelle_naf"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcab_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLIBELLE_NAF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcab_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAF_INDUSTRY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeo_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutcome_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffectif_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mape3_risk_overrepresentation_eff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_ape3_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrisk_ape3_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m"libelle_naf"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnaf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffectif_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrisk_ape3_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrisk_ape3_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m"libelle_naf"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnaf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeo_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m"libelle_naf"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m"libelle_ape3"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m"effectif_tot"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\'sum\'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffectif_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mrisk_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf"ape3_risk_eff_most_overrepresented_{naf}"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mape3_risk_overrepresentation_eff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeo_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutcome_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mrisk_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf"ape3_risk_eff_most_overrepresented_{naf}"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf"ape3_risk_eff_most_overrepresented_{naf}"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m"None"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n',
                        "\u001b[0;32m~/predictsignauxfaibles/env_predictSF/lib64/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(self, level, dropna)\u001b[0m\n\u001b[1;32m   7003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstack_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7004\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7005\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7007\u001b[0m     def explode(\n",
                        "\u001b[0;32m~/predictsignauxfaibles/env_predictSF/lib64/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(frame, level, dropna)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# we concatenate instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mdtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mIndexError\u001b[0m: list index out of range",
                    ],
                }
            ],
            "source": [
                'reg_risk_stats = aggregate_stats(geo_attr="region", outcome_attr="alert_flag")\n',
                'reg_riskbin_stats = aggregate_stats(geo_attr="region", outcome_attr="alert_bin")\n',
                'reg_fail_stats = aggregate_stats(geo_attr="region", outcome_attr="failure")\n',
                "\n",
                'dpt_risk_stats = aggregate_stats(geo_attr="departement", outcome_attr="alert_flag")\n',
                'dpt_riskbin_stats = aggregate_stats(geo_attr="departement", outcome_attr="alert_bin")\n',
                'dpt_fail_stats = aggregate_stats(geo_attr="departement", outcome_attr="failure")',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'reg_risque_rouge = reg_risk_stats[reg_risk_stats.index.get_level_values("alert_flag")==2]\n',
                'reg_risque_orange = reg_risk_stats[reg_risk_stats.index.get_level_values("alert_flag")==1]\n',
                'reg_risque_orange_ou_rouge = reg_riskbin_stats[reg_riskbin_stats.index.get_level_values("alert_bin")==True]\n',
                'reg_risque_vert = reg_riskbin_stats[reg_riskbin_stats.index.get_level_values("alert_bin")==False]\n',
                'reg_fail = reg_fail_stats[reg_fail_stats.index.get_level_values("failure")==True]\n',
                'reg_nofail = reg_fail_stats[reg_fail_stats.index.get_level_values("failure")==False]\n',
                "\n",
                'dpt_risque_rouge = dpt_risk_stats[dpt_risk_stats.index.get_level_values("alert_flag")==2]\n',
                'dpt_risque_orange = dpt_risk_stats[dpt_risk_stats.index.get_level_values("alert_flag")==1]\n',
                'dpt_risque_orange_ou_rouge = dpt_riskbin_stats[dpt_riskbin_stats.index.get_level_values("alert_bin")==True]\n',
                'dpt_risque_vert = dpt_riskbin_stats[dpt_riskbin_stats.index.get_level_values("alert_bin")==False]\n',
                'dpt_fail = dpt_fail_stats[dpt_fail_stats.index.get_level_values("failure")==True]\n',
                'dpt_nofail = dpt_fail_stats[dpt_fail_stats.index.get_level_values("failure")==False]',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'reg_risk_outpath_root = "/home/simon.lebastard/predictsignauxfaibles/data/reg_2103"\n',
                'dpt_risk_outpath_root = "/home/simon.lebastard/predictsignauxfaibles/data/dpt_2103"\n',
                "\n",
                'reg_risk_stats.to_csv(f"{reg_risk_outpath_root}_riskflag_all.csv")\n',
                'dpt_risk_stats.to_csv(f"{dpt_risk_outpath_root}_riskflag_all.csv")\n',
                'reg_riskbin_stats.to_csv(f"{reg_risk_outpath_root}_riskbin_all.csv")\n',
                'dpt_riskbin_stats.to_csv(f"{dpt_risk_outpath_root}_riskbin_all.csv")\n',
                'reg_fail_stats.to_csv(f"{reg_risk_outpath_root}_failures_all.csv")\n',
                'dpt_fail_stats.to_csv(f"{dpt_risk_outpath_root}_failures_all.csv")\n',
                "\n",
                'reg_risque_rouge.to_csv(f"{reg_risk_outpath_root}_risque_rouge.csv")\n',
                'reg_risque_orange.to_csv(f"{reg_risk_outpath_root}_risque_orange.csv")\n',
                'reg_risque_orange_ou_rouge.to_csv(f"{reg_risk_outpath_root}_risque_orange_ou_rouge.csv")\n',
                'reg_risque_vert.to_csv(f"{reg_risk_outpath_root}_risque_vert.csv")\n',
                'reg_fail.to_csv(f"{reg_risk_outpath_root}_defaillance.csv")\n',
                'reg_nofail.to_csv(f"{reg_risk_outpath_root}_sans_defaillance.csv")\n',
                "\n",
                'dpt_risque_rouge.to_csv(f"{dpt_risk_outpath_root}_risque_rouge.csv")\n',
                'dpt_risque_orange.to_csv(f"{dpt_risk_outpath_root}_risque_orange.csv")\n',
                'dpt_risque_orange_ou_rouge.to_csv(f"{dpt_risk_outpath_root}_risque_orange_ou_rouge.csv")\n',
                'dpt_risque_vert.to_csv(f"{dpt_risk_outpath_root}_risque_vert.csv")\n',
                'dpt_fail.to_csv(f"{dpt_risk_outpath_root}_defaillance.csv")\n',
                'dpt_nofail.to_csv(f"{dpt_risk_outpath_root}_sans_defaillance.csv")',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [],
        },
    ],
}
